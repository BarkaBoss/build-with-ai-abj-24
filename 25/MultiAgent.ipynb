{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a90b5820",
   "metadata": {},
   "source": [
    "## Multi-Agent System Using Langchain and Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74afa5bc",
   "metadata": {},
   "source": [
    "### Install the necessary libraries using pip\n",
    "\n",
    ">pip install langchain==0.3.24 langchain-google-genai==2.1.3 langchain_community tavily-python streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1419f6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "from api_key import api_key, tavily\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import Tool, initialize_agent, AgentType\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135eff9a",
   "metadata": {},
   "source": [
    "### Setup your environment with the necessary API Keys\n",
    "\n",
    "Google Gemini API at: https://aistudio.google.com/\n",
    "\n",
    "Tavily API Key at: https://app.tavily.com/home\n",
    "\n",
    "1. Once you have your API keys open api-key.py\n",
    "2. Fill the keys appropriately "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f233ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "os.environ[\"TAVILY_API_KEY\"] = tavily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1222d4",
   "metadata": {},
   "source": [
    "### Configure our LLM\n",
    "Langchain allows you intergrate with different types of LLM and AI platforms like OpenAI, Anthropic, Hugging Face etc\n",
    "\n",
    "For this lab we will be using Google Gemini\n",
    "\n",
    "we setup the parameters\n",
    "1. temperature which controls the creativity of our LLM ranging from 0.0 to 1.0\n",
    "2. model which is the version of Gemini we intend to use\n",
    "3. max_tokens, this is the response length limit of the model\n",
    "4. top_p, controls the range and diversity of the possible next words the model considers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8d35eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    temperature=0.7,\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    max_tokens=500,\n",
    "    top_p=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e52486",
   "metadata": {},
   "source": [
    "#### Searching through our data file \n",
    "To find if the requested item and quantity are available, this will be used to create a custom tool for our inventory agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a251afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_inventory(item, quantity, csv_file=\"shop.csv\"):\n",
    "    \"\"\"\n",
    "    Checks the inventory for the availability of a specific item and quantity.\n",
    "\n",
    "    Args:\n",
    "      item (str): The name of the item to check in the inventory.\n",
    "      quantity (int): The quantity of the item to check for availability.\n",
    "      csv_file (str, optional): The path to the CSV file containing inventory data. \n",
    "                    Defaults to \"shop.csv\".\n",
    "\n",
    "    Returns:\n",
    "      str: A message indicating whether the requested item and quantity are available, \n",
    "         the available stock if insufficient, or an error message if an exception occurs.\n",
    "\n",
    "    Notes:\n",
    "      - The CSV file is expected to have columns \"item\" and \"quantity\".\n",
    "      - The function performs a case-insensitive comparison for the item name.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(csv_file, newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                if row[\"item\"].lower() == item.lower():\n",
    "                    available = int(row[\"quantity\"])\n",
    "                    if available >= int(quantity):\n",
    "                        return f\"{item.title()} is available. Requested: {quantity}, In stock: {available}.\"\n",
    "                    else:\n",
    "                        return f\"Only {available} units of {item} are available. Requested: {quantity}.\"\n",
    "        #return f\"{item.title()} is not in stock.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error checking inventory: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f4cf8f",
   "metadata": {},
   "source": [
    ">Recieve text input and extracts the quantity and item from user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d876ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inventory_check_natural_language(input_text):\n",
    "    \"\"\"\n",
    "    Parses a natural language input string to extract an item and its quantity, \n",
    "    and checks the inventory for the specified item and quantity.\n",
    "\n",
    "    The function looks for patterns in the input text that specify a quantity \n",
    "    followed by an item name, optionally followed by \"are\" or \"is\" and \"available\". \n",
    "    If a match is found, it extracts the quantity and item name, and calls the \n",
    "    `check_inventory` function with these values. If no match is found, it \n",
    "    returns an error message.\n",
    "\n",
    "    Args:\n",
    "      input_text (str): A natural language string describing the item and quantity \n",
    "                to check in the inventory.\n",
    "\n",
    "    Returns:\n",
    "      str: The result of the `check_inventory` function if parsing is successful, \n",
    "         or an error message if parsing fails.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    match = re.search(r\"(\\d+)\\s+(.+?)\\s*(?:are|is)?\\s*available\", input_text.lower())\n",
    "    if match:\n",
    "        quantity = int(match.group(1))\n",
    "        item = match.group(2).strip()\n",
    "        return check_inventory(item, quantity)\n",
    "    else:\n",
    "        return \"Could not parse item and quantity from input.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0ecb4c",
   "metadata": {},
   "source": [
    "#### Create our inventory tool\n",
    "1. we name our inventory tool \"Inventory Checker\n",
    "2. we pass our custom function as the action of this tool\n",
    "3. the description of the tool is now clearly stated, this improves the effciency of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1e76d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_tool = Tool(\n",
    "    name=\"Inventory Checker\",\n",
    "    func=inventory_check_natural_language,\n",
    "    description=\"Use this tool to check the inventory for a specific item and quantity. \"\n",
    "                \"Input should be in the format: 'X items are available' or 'X items is available'. \"\n",
    "                \"Example: '5 apples are available'.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421826f0",
   "metadata": {},
   "source": [
    "#### Setup our Search tool\n",
    "1. First create a search_tool property of TavilySearchResults\n",
    "2. We set our max results to 3 (could be higher or less)\n",
    "3. Then proceed to create the nutrition_tool of type Tool\n",
    "4. Note that we set the function of this tool to **search_tool.run()** to start the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabab313",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = TavilySearchResults(max_results=3)\n",
    "nutrition_tool = Tool(\n",
    "    name=\"Nutrition Info\",\n",
    "    func=lambda query: search_tool.run(f\"Nutritional information of {query}\"),\n",
    "    description=\"Gives the nutrition facts of a given item.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122c7f1c",
   "metadata": {},
   "source": [
    "## Pheeew that has been a lot to take it\n",
    "> Drink some water"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f1f12a",
   "metadata": {},
   "source": [
    "## Time to create and equip our agents \n",
    "\n",
    "For the most part our models have similar features like:\n",
    ">1. agent being set to CHAT_ZERO_SHOT_REACT_DESCRIPTION (An agent that interacts in a conversational manner and can use tools it has not been explicitly trained on by relying on the tools description) **there are lots of other types of Agent**\n",
    ">2. memory set to ConversationBufferMemory(memory_key=\"chat_history\") this way our model maintains the context of the current query with the key \"chat_history\"\n",
    ">3. verbose set to False (we will set this to true later to view our model's reasoning)\n",
    "\n",
    "Our conversation agent has no tools but our **inventory_agent has the inventory_tool** and the **nutrition_agent has the nutrition_tool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c77aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_agent = initialize_agent(\n",
    "    tools=[],\n",
    "    llm=llm,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    memory=ConversationBufferMemory(memory_key=\"chat_history\"),\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c1a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_agent = initialize_agent(\n",
    "    tools=[inventory_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    memory=ConversationBufferMemory(memory_key=\"chat_history\"),\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd48816",
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrition_agent = initialize_agent(\n",
    "    tools=[nutrition_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    memory=ConversationBufferMemory(memory_key=\"chat_history\"),\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808af019",
   "metadata": {},
   "source": [
    "## Running our Agents 🤖🤖🤖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a48c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agents(item: str, quantity: int):\n",
    "    convo = conversation_agent.run(f\"Tell me what an {item} is.\")\n",
    "    stock_query = f\"Check if {quantity} {item}(s) are available in stock.\"\n",
    "    stock = inventory_agent.run(stock_query)\n",
    "    nutrition = nutrition_agent.run(item)\n",
    "    return convo, stock, nutrition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c84147e",
   "metadata": {},
   "source": [
    "# Congratulations!!! 🥳\n",
    "\n",
    "### run your code with\n",
    "> **streamlit run front_end.py**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
